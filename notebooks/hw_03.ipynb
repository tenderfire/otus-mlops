{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51ae4c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b87d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"OTUS\")\n",
    "        .config(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "        .config(\"spark.executor.memory\", \"2g\")\n",
    "        .config(\"spark.driver.memory\", \"1g\")\n",
    "        .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53c3aee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tranaction_id | tx_datetime | customer_id | terminal_id | tx_amount | tx_time_seconds | tx_time_days | tx_fraud | tx_fraud_scenario\n",
      "1832792610,2022-11-04 14:22:18,0,53,63.58,101139738,1170,0,0\n",
      "1832792611,2022-11-04 02:12:24,0,53,92.95,101095944,1170,0,0\n",
      "1832792612,2022-11-04 12:49:35,3,205,48.88,101134175,1170,0,0\n",
      "1832792613,2022-11-04 02:40:01,5,383,24.69,101097601,1170,0,0\n",
      "1832792614,2022-11-04 08:02:05,6,858,95.48,101116925,1170,0,0\n",
      "1832792615,2022-11-04 05:45:04,8,931,60.98,101108704,1170,0,0\n",
      "1832792616,2022-11-04 20:01:50,8,931,28.48,101160110,1170,0,0\n",
      "1832792617,2022-11-04 15:11:42,9,450,7.89,101142702,1170,0,0\n",
      "1832792618,2022-11-04 11:20:49,10,549,63.37,101128849,1170,0,0\n",
      "1832792619,2022-11-04 23:11:46,10,549,78.02,101171506,1170,0,0\n",
      "1832792620,2022-11-04 10:26:06,11,337,68.54,101125566,1170,0,0\n",
      "1832792621,2022-11-04 14:13:55,11,337,12.04,101139235,1170,0,0\n",
      "1832792622,2022-11-04 04:17:01,11,975,76.00,101103421,1170,0,0\n",
      "1832792623,2022-11-04 07:39:18,11,975,12.08,101115558,1170,0,0\n",
      "1832792624,2022-11-04 10:02:03,12,745,29.19,101124123,1170,0,0\n",
      "1832792625,2022-11-04 08:13:21,12,745,110.49,101117601,1170,0,0\n",
      "1832792626,2022-11-04 11:11:49,12,745,165.48,101128309,1170,0,0\n",
      "1832792627,2022-11-04 08:14:10,13,559,69.20,101117650,1170,0,0\n",
      "1832792628,2022-11-04 11:59:01,14,186,12.86,101131141,1170,0,0\n",
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "# Используем системную команду head для просмотра файла на HDFS\n",
    "!hdfs dfs -cat data/2022-11-04.txt | head -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Файл имеет заголовок с разделителем '|', но данные с разделителем ','\n",
    "# Опеределяем схему\n",
    "from pyspark.sql.types import StructType, StructField, LongType, StringType, DoubleType, IntegerType, TimestampType\n",
    "from pyspark.sql.functions import col, to_timestamp\n",
    "\n",
    "# Вариант 1: Читаем datetime как строку, потом конвертируем\n",
    "schema = StructType([\n",
    "    StructField(\"tranaction_id\", LongType(), True),\n",
    "    StructField(\"tx_datetime\", StringType(), True),  # сначала как строка\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"terminal_id\", IntegerType(), True),\n",
    "    StructField(\"tx_amount\", DoubleType(), True),\n",
    "    StructField(\"tx_time_seconds\", LongType(), True),\n",
    "    StructField(\"tx_time_days\", IntegerType(), True),\n",
    "    StructField(\"tx_fraud\", IntegerType(), True),\n",
    "    StructField(\"tx_fraud_scenario\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Читаем файл и конвертируем datetime в правильный тип\n",
    "df = (\n",
    "    spark.read.csv(\n",
    "        \"data/2022-11-04.txt\",\n",
    "        sep=\",\",           # разделитель - запятая\n",
    "        schema=schema      # используем определённую схему\n",
    "    )\n",
    "    .filter(col(\"tranaction_id\").isNotNull())  # убираем строку с заголовком\n",
    "    .withColumn(\"tx_datetime\", to_timestamp(\"tx_datetime\", \"yyyy-MM-dd HH:mm:ss\"))  # конвертируем в timestamp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c519ea7",
   "metadata": {},
   "source": [
    "Проверим схему данных с правильным типом datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56e9618f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1e4846eda7dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Проверим типы данных\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Посмотрим на данные\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Проверим типы данных\n",
    "df.printSchema()\n",
    "\n",
    "# Посмотрим на данные\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5df84a",
   "metadata": {},
   "source": [
    "### Преимущества использования TimestampType:\n",
    "1. **Меньше места** в parquet (эффективное хранение)\n",
    "2. **Быстрые операции** с датами (фильтрация, сортировка, группировка)\n",
    "3. **Встроенные функции** для работы с датами (year, month, day, hour и т.д.)\n",
    "4. **Автоматическая валидация** формата даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85622519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример работы с datetime колонкой\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, minute, dayofweek\n",
    "\n",
    "# Извлечём различные компоненты даты\n",
    "df.select(\n",
    "    \"tx_datetime\",\n",
    "    year(\"tx_datetime\").alias(\"year\"),\n",
    "    month(\"tx_datetime\").alias(\"month\"),\n",
    "    dayofmonth(\"tx_datetime\").alias(\"day\"),\n",
    "    hour(\"tx_datetime\").alias(\"hour\"),\n",
    "    minute(\"tx_datetime\").alias(\"minute\"),\n",
    "    dayofweek(\"tx_datetime\").alias(\"day_of_week\")  # 1 = Воскресенье, 7 = Суббота\n",
    ").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a0c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним в parquet\n",
    "(\n",
    "    riiid_df\n",
    "        .write\n",
    "        .mode(\"overwrite\")\n",
    "        .parquet(\"data/2022-11-04.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa84477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим содержимое директории parquet\n",
    "!hdfs dfs -ls data/2022-11-04.parquet\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Размер файлов внутри parquet директории:\")\n",
    "print(\"=\"*50)\n",
    "!hdfs dfs -du -h data/2022-11-04.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba70b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество записей в parquet: 46998983\n",
      "Схема данных:\n",
      "root\n",
      " |-- tranaction_id: long (nullable = true)\n",
      " |-- tx_datetime: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- terminal_id: integer (nullable = true)\n",
      " |-- tx_amount: double (nullable = true)\n",
      " |-- tx_time_seconds: long (nullable = true)\n",
      " |-- tx_time_days: integer (nullable = true)\n",
      " |-- tx_fraud: integer (nullable = true)\n",
      " |-- tx_fraud_scenario: integer (nullable = true)\n",
      "\n",
      "\n",
      "Первые 5 записей:\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|tranaction_id|        tx_datetime|customer_id|terminal_id|tx_amount|tx_time_seconds|tx_time_days|tx_fraud|tx_fraud_scenario|\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|   1838826044|2022-11-07 15:08:53|     850577|        324|    65.72|      101401733|        1173|       0|                0|\n",
      "|   1838826045|2022-11-07 15:09:45|     850579|        734|    83.88|      101401785|        1173|       0|                0|\n",
      "|   1838826046|2022-11-07 12:29:14|     850579|        533|    87.64|      101392154|        1173|       0|                0|\n",
      "|   1838826047|2022-11-07 06:50:02|     850580|        826|     3.81|      101371802|        1173|       0|                0|\n",
      "|   1838826048|2022-11-07 11:08:58|     850581|        115|    50.42|      101387338|        1173|       1|                2|\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|tranaction_id|        tx_datetime|customer_id|terminal_id|tx_amount|tx_time_seconds|tx_time_days|tx_fraud|tx_fraud_scenario|\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|   1838826044|2022-11-07 15:08:53|     850577|        324|    65.72|      101401733|        1173|       0|                0|\n",
      "|   1838826045|2022-11-07 15:09:45|     850579|        734|    83.88|      101401785|        1173|       0|                0|\n",
      "|   1838826046|2022-11-07 12:29:14|     850579|        533|    87.64|      101392154|        1173|       0|                0|\n",
      "|   1838826047|2022-11-07 06:50:02|     850580|        826|     3.81|      101371802|        1173|       0|                0|\n",
      "|   1838826048|2022-11-07 11:08:58|     850581|        115|    50.42|      101387338|        1173|       1|                2|\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Читаем parquet обратно\n",
    "df_from_parquet = spark.read.parquet(\"data/2022-11-04.parquet\")\n",
    "\n",
    "print(f\"Количество записей в parquet: {df_from_parquet.count()}\")\n",
    "print(f\"Схема данных:\")\n",
    "df_from_parquet.printSchema()\n",
    "print(\"\\nПервые 5 записей:\")\n",
    "df_from_parquet.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
